#### ISO七层网络模型

![img](计算机网络.assets\v2-854e3df8ea850c977c30cb1deb1f64db_720w.jpg)



#### TCP/IP四层模型

1. 网络接口层

以太网协议(MAC地址)、ARP协议

2. 网络层

IP协议、ICMP协议

3. 传输层

TCP协议、UDP协议

4. 应用层

HTTP协议、FTP协议、SMTP协议



#### TCP/IP数据包

![img](计算机网络.assets\v2-b336a50e1d671a5ef82f532c492474fe_720w.jpg)

**TCP包头部**

1. 16位端口号(port number)

2. 32位序号(sequence number)：用来解决包**乱序问题**

3. 32位确认号(acknowledgement number)：用来解决**丢包问题**

4. 4位头部长度(header length)：标识该TCP头部有多少个32bit(4Byte)，因为4位最多能表示15，所以TCP头部最长是60Byte

5. 6位标志位

   (1) URG，表示紧急指针是否有效

   (2) ACK，表示确认号是否有效，携带此标志的TCP报文段为“确认报文段”

   (3) PSH，提示接收端应用程序应该立即从TCP接收缓冲区中读走数据，为接收后续数据腾出空间

   (4) RST，表示要求对方重新建立连接，携带此标志的TCP报文段为“复位报文段”

   (5) SYN，表示请求建立一个连接，携带此标志的TCP报文段为"同步报文段"

   (6) FIN，表示通知对方本端要关闭连接了，携带此标志的TCP报文段为“结束报文段”

6. 16位窗口大小(window size)：TCP**流量控制**的手段。它告知对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度
7. 16位校验和(checksum)：TCP**可靠传输**的一个重要保障。由发送端填充，接收端通过算法来检验TCP报文段在传输过程中是否损坏
8. 16位紧急指针(urgent pointer)

**注意：**

> TCP的包是没有IP地址的，只有端口号

#### TCP与UDP

**TCP的特点：**

* TCP是**面向连接**的
* 每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点**一对一**的
* TCP提供**可靠交付**的服务。通过TCP连接传送的数据，无差错、不丢失、不重复，并且按序列到达
* TCP提供**全双工通信**。TCP允许通信双方的应用进程在任何时候都能**同时发送和接收**数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据
* 面向字节流。

**UDP的特点：**

* UDP是**无连接**的
* UDP使用尽最大努力交付，即**不保证可靠交付**，因此主机不需要维持复杂的链接状态
* UDP**没有拥塞控制**。因此网络出现拥塞不会使源主机的发送速率降低（对**实时应用**很有用，例如直播、视频会议等）
* UDP支持**一对一、一对多、多对一和多对多**的交互通信
* UDP的**首部开销较小**，只有8个字节，比TCP的20个字节的首部要短
* UDP是面向报文的

**TCP与UDP的区别：**

* TCP提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或多播服务。TCP的可靠性体现在TCP在传输数据之前，会有**三次握手来建立连接**，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会**断开连接**来节约系统资源。这难以避免增加了许多开销，如确认、流量控制、计时器以及连接管理等。这不仅使得协议**首部增大很多**，还要**占用许多处理资源**
* UDP在传送数据之前不需要先建立连接。远地主机在收到UDP报文后，**不需要给出任何确认**。虽然UDP不提供可靠交付，但在某些情况下UDP却是一种有效的工作方式，一般用于**即时通信**，如QQ语音、QQ视频、直播等

#### TCP三次握手

![img](计算机网络.assets\v2-1c5da3391ad30aa7aa30f9362407a77f_b.jpg)

注：TCP各头部标志位含义

* ACK：表示确认号是否有效，含ACK标志的TCP报文段为“确认报文段”
* SYN：表示请求建立一个连接，含SYN标志的TCP报文段为“同步报文段”
* FIN：表示通知对方本端要关闭连接了，含FIN标志的TCP报文段为“结束报文段”

最初客户端和服务端都处于`CLOSED(关闭)`状态，假设A(Client)主动打开连接，B(Server)被动打开连接

一开始，B的TCP服务器进程首先创建传输控制板块TCB，准备接收客户端进程的连接请求。然后服务端进程就处于`LISTEN(监听)`状态，等待客户端的连接请求

**SYN(Sequence Number)**：这个号要作为数据通信的序号，以保证应用层接收到的数据不会因为网络上的传输问题而乱序（TCP会用这个序号来拼接数据）

* **第一次握手**：A的TCP客户端进程也是首先创建传输控制模块TCB。然后，在打算建立TCP连接时，向B发出连接请求报文段，这时首部中的同步位`SYN=1`，同时选择一个初始序号`seq=x`。TCP规定，SYN报文段不能携带数据，但要消耗一个序列号。这使，TCP客户进程进入`SYN-SENT(同步已发送)`状态
* **第二次握手**：B收到连接请求报文后，如果同意建立连接，则向A发送确认。在确认报文中把`SYN和ACK都置为1`，确认号是`ack=x+1`，同时也为自己选择一个初始序号`seq=y`。这个报文段也不能携带数据，但同时要消耗一个序号。这时TCP服务端进程进入`SYN-RCVD(同步收到)`状态
* **第三次握手**：TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的`ACK置为1`，确认号`ack=y+1`，而自己的序列号`seq=x+1`。这时，TCP连接已经建立，A进入`ESTABLISHED(已建立连接)`状态

**为什么两次握手不可以？**

主要是要初始化`Sequence Number`的初始值。通信双方要互相通知对方自己SYN的初始值

此外，为了防止已经失效的连接请求报文突然又传送到了B，因而产生错误。例如，A发出的第一个连接请求报文段并没有丢失，而是在网路节点长时间滞留了，以致于延误到连接释放以后的某个时间段才到达B，这本是一个**早已失效的报文段**。但B收到后，就会误以为A发出了一次新的连接请求，同意建立连接。如果没有第三次握手，B就会一直在等待A发来数据，导致B的许多资源浪费了

**为什么不需要四次握手？**

**完全可靠的通信协议是不存在的**。没有必要再增加次数

#### TCP四次挥手

![img](计算机网络.assets\v2-dc0bdc69237df055ff8c2aa477887237_b-1584178444045.jpg)

传输结束后，通信的双方都可以释放连接。现在A和B都处于`ESTABLISHED`状态

* **第一次挥手**：A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位`FIN置1`，其序号`seq=u`（等于前面已传送过的数据的最后一个字节的序号加1）。这时，A进入`FIN-WAIT-1(终止等待1)`状态，等待B的确认。注意，FIN报文段即使不携带数据，也将消耗一个序号
* **第二次挥手**：B收到连接释放报文段后立即发出确认，确认号是`ack=u+1`，而这个报文段自己的序号是`seq=v`（等于B前面已经传送过的数据的最后一个字节的序号加1）。然后，B进入`CLOSED-WAIT(关闭等待)`状态。TCP服务端进程这时应该通知高层应用进程，因而从A到B方向上的连接就释放了，这时TCP连接处于**半关闭(half-close)**状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，从B到A方向的连接并未关闭，这个状态可能持续一段时间。A收到来自B的确认后，进入`FIN-WAIT-2(终止等待2)`状态，等待B发出的连接释放报文段
* **第三次挥手**：若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这时B发出的连接释放报文段必须使`FIN=1`。假定B的序号为w（在半关闭状态，B可能又发送了一些数据），B还必须重复上次发送过的确认好`ack=u+1`，这时B就进入`LAST-ACK(最后确认)`状态，等待A的确认
* **第四次挥手**：A在收到B的连接释放报文后，必须对此发出确认。在报文段中把ACK置1，确认号`ack=w+1`，自己的序列号为`seq=u+1`（第一次挥手发送的FIN消耗一个序号）。然后进入`TIME-WAIT(时间等待)`状态。注意，现在的TCP连接还没有释放掉，必须等待计时器设置的时间2MSL后，A才能进入到CLOSED状态，然后撤销传输控制块TCB，结束此次TCP连接。所以，**B结束TCP连接的状态要早于A**

**为什么TIME-WAIT状态必须等待2MSL的时间？**

* 为了保证A发送的最后一个ACK报文段能到达B。这个ACK报文段**可能丢失**，因而处于LAST-ACK状态的B收不到对FIN+ACK报文段的确认，B会**超时重传**，而A就能在2MSL时间内收到这个重传的FIN-ACK报文段，接着A重传一次确认，重新启动2MSL计时器
* 防止已失效的连接请求报文段出现在本连接中。A发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有报文段都在网络中消失，使得下一个连接中不会出现这种旧的连接请求报文段

**为什么第二次和第三次不能合并？**

服务器执行第二次挥手后，证明客户端不会再向服务端发送数据，但服务端可能还正在给客户端发送数据（可能客户端上一次请求的资源还没有发送完毕），所以此时服务端会等待把之前未传输完成的数据传输完毕之后再发送关闭请求

#### TCP协议是如何保证可靠传输的

* 数据包检验：检测数据在传输过程中的任何变化，若检验出数据包有错，则丢弃报文段并且不给出响应，这时TCP发送数据段会超时重发
* 对失序数据包重排列：TCP对失序数据进行重新排序后，才交给应用层
* 丢失重复数据：对于重复数据，能够丢弃
* 应答机制：TCP收到自TCP连接另一端的数据时，它将发送一个确认。不是立即发送，通常推迟几分之一秒
* 超时重发：当TCP发出一个段后，它启动一个定时器，等待对方确认后收到这个报文段并发回确认。如果不能及时收到确认，将重发这个报文段
* 流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能容纳的数据，这可以防止快主机致使慢主机的缓冲区溢出。TCP使用的流量控制协议是可变大小的滑动窗口协议

#### MSL、TTL与RTT

1. MSL(Maximum Segment Lifetime)

即报文最大生存时间，是指任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃

在不同系统中MSL的大小不同，一般Windows: 2 min, Linux: 60s, Unix: 30s

2. TTL(Time to Live)

即生存时间，这个生存时间是由源主机设置初始值，但它不是一个具体时间，而是表示一个ip数据报可以经过的最大路由数，每经过一个路由器此值就-1，当此值为0则数据报被丢弃，同时发送ICMP报文通知源主机

其设置是为了防止数据包在网络上永不终止地循环

3. RTT(Round-Trip Time)

RTT是数据从客户端到服务端**往返**所花的时间

#### MTU与MSS

1. MTU(Maximum Transmission Unit)

数据链路层传输的帧大小是有限制的，不能把一个太大的包直接塞给链路层，这个限制被称为**最大传输单元MTU**，一般为1500字节

不同数据链路层的MTU也是不同的，IP协议的数据报最大为65535个字节，远远超过了MTU的值，因此需要对数据进行**分片**，这也是IP协议的主要功能之一

3. MSS(Max Segment Size)

TCP为了避免被发送方分片，它主动把数据分成小段再交给网络层，最大的分段即MSS。它相当于把MTU减去IP头和TCP头的大小，所以一个MSS恰好能装进一个MTU中

![img](D:\文件\markdown笔记\计算机网络.assets\v2-5c578bd8beb44dd6a2755ce989f9a2d5_b.jpg)



#### TCP流量控制

**糊涂窗口综合征**

1. 发送端产生原因及症状

如果发送端是**产生数据很慢**的应用程序服务，例如，一次产生一个字节。如果没有特定指令，它就产生只包括一个字节数据的报文段，结果有很多41字节（IP头部和TCP头部各20字节）的IP数据报就在传来传去

2. 解决办法

**Nagle算法**：发送端的发送缓存数据积累到可以组成一个较大报文段时，或者收到接收端的ACK时，再发送。算法简单，但是考虑到了应用程序产生数据的速率，以及网络传输数据的速率。如果应用程序比网络更快，则报文段就更大；如果应用程序比网络慢，则报文段就小

3. 接收端产生的症状

如果接受端为**消耗数据很慢**的应用程序服务，例如，一次消耗一个字节。接收端很快缓存就满了，每次消耗一个字节数据后，宣布窗口大小为一个字节，于是发送端只能发送一个字节

4. 解决办法

**Clark算法**：只要有数据到达就发送确认，但宣布窗口大小为零，直到缓存空间已经能放入具有最大长度的报文段，或者缓存空间的一半已经空了

**延迟确认**：延迟一段时间后再发送ACK，这样当发送端的TCP发送完数据后，就停下来了，同时也减少了通信量。但缺点是，延迟确认可能会让发送端超时重传

#### TCP拥塞控制

**拥塞控制和流量控制不同**

* 拥塞控制是一个**全局性**的过程，而流量控制指点对点的通信量的控制。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫拥塞

* 拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不至于过载。拥塞控制涉及到所有的主机、所有的路由器以及与降低网络传输性能有关的所有因素。而流量控制要做到的就是**抑制发送端到端数据的速率**，以使接收端来得及接收

为了进行拥塞控制，TCP发送方要维持一个拥塞窗口`cwnd`的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口中较小的一个

TCP的拥塞控制采用了四种算法：

* **慢开始**：思路是当主机开始发送数据时，因为还不知道网络的情况，如果立即把大量数据字节注入到网络，很可能会引起网络堵塞。一般是先探测一下，即有小到大逐渐增大发送窗口，`cwnd`初值为1 MSS。每收到一个ACK后，就`cwnd += 1`。那么实际上每经过一个传播轮次(1 RTT)，`cwnd加倍`
* **拥塞避免**：当`cwnd`指数增长到慢开始门限`ssthresh`时，开始缓慢增大，每个RTT增加1

当网络发生拥塞时，`ssthresh /= 2`，`cwnd`=1

* **快重传**：快重传是指接收方在收到一个失序的报文段后，就立即发出重复确认，而不需要等到自己发送数据时捎带确认。算法规定，发送方只要一连收到3个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期
* **快恢复**：发送方连续收到3个重复确认时，执行“乘法减小”算法，即`ssthresh /= 2`。考虑到如果网络拥塞的话不会连续收到几个重复确认，所以发送方认为现在网络可能没有出现拥塞，故并不执行慢开始，而是执行`cwnd = ssthresh`，然后开始拥塞避免算法，每次增加1

#### 网络IO模型

同步和异步关注的是**消息通信机制**

* 同步IO：发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了
* 异步IO：调用发出之后，这个调用就直接返回了，所以没有返回结果。即调用者不会立即得到结果，而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用

阻塞和非阻塞关注的是**程序在等待调用结果时的状态**

* 阻塞：调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才返回
* 非阻塞：不能立即得到结果之前，该调用不会阻塞当前进程

##### 4种IO模型

1. 阻塞IO模型

2. 非阻塞IO模型
3. 多路IO复用模型
4. 异步IO模型

**阻塞IO模型**

![img](计算机网络.assets\J$IM%Z_AL9ND53]H0V]UQ.png)

IO执行的两个阶段（等待数据和拷贝数据）都被阻塞了

大部分的socket接口都是阻塞型的，即系统调用时不返回结果，并让当前线程一直处于阻塞状态，只有当该系统调用获得结果或者超时出错时才返回结果

实际上，几乎所有的IO接口（包括socket接口）都是阻塞型的

简单的改进方案：服务器端使用**多线程（或多进程）——线程池、进程池**

但面对大规模的服务请求，多线程模型也会遇到瓶颈，可以用非阻塞模型来解决

**非阻塞IO模型**

![img](计算机网络.assets\7`1BSHDSP$}S9M_RS%OKNJH.png)

在非阻塞IO中，用户进程其实需要不断主动地询问kernel数据是否准备好

服务器线程可以通过循环调用`recv()`接口，在单个线程内实现对所有连接的数据接收工作。但此模型**绝不被推荐**，因为循环调用将大幅度占用CPU使用率

**多路IO复用模型**

![image](D:\文件\markdown笔记\计算机网络.assets\3.png)

多路IO复用，有时也被成为**事件驱动IO**。它的基本原理就是有个函数（如select）会不断地查询所负责的所有socket，当某个socket有数据到达了，就通知用户进程

这个模型和阻塞IO模型其实并没有太大的不同，事实上还会更差一点，因为这里需要使用两个系统调用（`select`和`recvfrom`），而阻塞IO只调用一个

`select`的优势在于它可以同时处理**多个连接**

**异步IO模型**

![img](计算机网络.assets\2.png)

用户进程发起read操作后，立刻可以去做其他事；从内核的角度，当它收到一个异步的read请求操作后，首先会立刻返回，所以不会对进程产生任何阻塞。然后内核会等待数据准备完成，然后将数据拷贝到用户内存中，当这一切完成后，内核会给用户发一个信号，返回read操作已完成的信息

其实按照这个分类，之前的阻塞IO、非阻塞IO以及多路复用IO都属于同步IO

##### select/poll/epoll

select、poll和epoll都是**多路IO复用**的机制，都是**同步IO**

**三者对比：**

首先还是来看最常见的select()和poll()，对于网络编程来说，一般认为poll()比select()要高级一些，主要源于：

* poll()不要求开发者在计算最大文件描述符时+1的操作

* poll()在应付大数目的文件描述符的时候速度更快
* select()可以监控的文件描述符数目是固定的，相对来说也比较少（1024或2048）。如果需要监控数值较大的文件描述符，或是分布得很稀疏的较少的描述符，效率也会很低。而对于poll()函数来说，可以创建特定大小的数组来保存监控的描述符，而不受文件描述符大小的影响，而且poll()可以监控的文件数目远大于select()
* select()函数的超时参数在返回时也是未定义的，考虑到可移植性，每次在超时之后在下一次进入到select()之前都需要重新设置超时参数

select()的优点：

* select()的可移植性更好，某些UNIX()系统上不支持poll()
* select()对于超时值提供了更好的精度，而poll()精度较差

epoll()的优点：

* 支持一个进程打开大数目的socket描述符（FD）
* IO效率不随FD数目增加而线性下降。传统select/poll的一个致命弱点就是，当你拥有一个很大的socket集合，由于网络的延迟，任一时间只有一部分socket是“活跃”的，但是select/poll每次调用都会线性扫描全部的集合，导致效率线性下降。但epoll每次只会对“活跃”的socket进行操作——这是因为在内核中实现epoll是根据每个FD上面的callback函数实现的，只有“活跃”的socket才会主动去调用callback函数
* 使用`mmap`加速内核和用户空间的消息传递

#### HTTP协议

HTTP/1.1协议中定义了9种方法来表明Request-URI指定的资源的不同操作方式，分别是：OPTIONS/HEAD/GET/POST/PUT/DELETE/TRACE/CONNECT/PATCH

##### GET和POST

GET与POST的区别

* 最直观的即语义上的区别，GET用于获取数据，POST用于提交数据

* GET请求的数据会附在URL之后，以?分割URL和传输数据，参数之间以&相连；POST把提交的数据放置在HTTP包的包体中
* GET有长度限制，受限于URL的长度，其取决于浏览器和服务器，而POST无限制

* 表面上看，POST的安全性比GET高，但实际上如果是HTTP协议，都是明文传输，都是不安全的

GET与POST的选择

* 私密性的信息请求使用POST，查询信息和想要通过URL分享的信息使用GET

##### 返回码

返回码由3位数字组成，第一个数字定义了响应的组别，其由5种可能的取值

(1) 1xx：指示信息，表示请求已接收，继续处理

(2) 2xx：成功，表示请求已被成功接收、理解和接受

(3) 3xx：重定向，要完成请求必须进行更进一步的操作

(4) 4xx：客户端错误，请求有语法错误或请求无法实现

(5) 5xx：服务器端错误，服务器未能实现合法的请求

常见状态码及和其状态描述说明：

> 200  OK							//请求成功
>
> 400  Bad Request		   //客户端请求有语法错误，服务器端无法理解
>
> 401  Unauthorized		 //请求未经授权
>
> 403  Forbidden				//服务器拒绝提供服务
>
> 404  Not Found				//请求资源不存在，比如输入了错误的URL
>
> 500  Internal Server Error		//服务器发生不可预期的错误
>
> 503  Server Unavailable			//服务器当前不能处理客户端的请求，一段时间后可能恢复

#### HTTP/2、HTTP/1.1和HTTP/1.0的区别

**HTTP/1.1**

1. **缓存处理**。新增了更多的缓存控制策略
2. **错误状态管理**。HTTP/1.1新增了24个错误状态响应码，如409(Conflict)表示请求的资源与资源的当前状态发生冲突，410(Gone)表示服务器上的某个资源被永久性的删除
3. **Host头**。HTTP/1.0中认为每台服务器绑定一个唯一的IP地址，因此在请求消息的URL中并没有传递主机名。而随着虚拟主机技术的发展，在一台物理服务器上可以存着多个虚拟主机(Multi-homed Web Servers)，并且它们共享一个IP地址。HTTP/1.1的请求消息和相应消息都应该支持Host头域，**请求消息的URL中必须传递主机名(Hostname)**，如果没有的话会返回错误(400 Bad Request)
4. **长连接和请求流水线处理**。在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。HTTP/1.1**默认开启Connection: keep-alive**，一定程度上弥补了HTTP1.0每次请求都要创建连接的特点。但是由于连接中发送的请求还是按照顺序处理，这样的话一旦有一个请求处理很久，那后面的处理就会被阻塞，这被称为“**队头阻塞**''

**HTTP/2**

HTTP/2没有下一个子版本，因此它不叫HTTP/2.0

注意，HTTP/2协议只有在HTTPS环境下才有效，要升级到HTTP/2，必须先启用HTTPS

HTTP/2解决了HTTP/1.1的性能问题，主要特点如下：

1. **二进制分帧**。HTTP/1.1的头信息是文本(ASCII码)，数据体可以是文本，也可以是二进制。HTTP/2头部信息和数据体都采用二进制，统称为"帧"，即投信息帧和数据帧
2. **数据流**。因为HTTP/2的数据报是不按顺序发送的，同一个连接里面连续的数据包可能属于不同的回应。HTTP/2将每个请求或回应的所有数据包，称为一个数据流。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流ID
3. **多路复用**。通过单一的HTTP/2连接发起多重的请求-相应消息，即在一个连接里，客户端和浏览器都可以同时发送多个请求和相应，而不是按照顺序一一对应，这样避免了"队头阻塞"
4. **首部压缩**。HTTP协议不带有状态，每次请求都必须附上所有信息，但请求的很多字段都是重复的，这样会浪费很多带宽。HTTP/2对这一点进行了优化，引入了头信息压缩机制。一方面，头信息压缩后再发送；另一方面，客户端和服务端同时维护一张头信息表，所有字段都会存入这个表，并且生成相应索引号，这样以后就不用发送同样字段了，只需要发送索引号

5. **支持服务器推送**。HTTP/2支持在客户端未经请求许可的情况下，主动向客户端推送内容

#### HTTPS和HTTP的区别

1. HTTPS协议需要到CA申请证书，一般免费证书很少，需要交费
2. HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，然后再运行在TCP之上，所有传输的内容都经过加密
3. HTTP和HTTPS使用的是完全不同的连接方式，用的端口号也不一样，HTTP是80，HTTPS是443
4. HTTPS可以有效防止信息劫持

#### 浏览器输入URL回车后发生了什么

##### 1. URL解析

**地址解析**

首先判断你输入的是一个合法的URL，还是一个待搜索的关键词，并且根据你输入的内容进行自动完成、字符编码等操作

**HSTS**(HTTP Strict Transport Security，一种新的Web安全协议)

如果网站采用了HSTS协议，就会强制浏览器使用HTTPS与服务器创建连接

**其他操作**

安全检查、访问限制等

**检查缓存**

如果浏览器内有相关内容的缓存，且没有过期，就直接返回缓存，不需要向服务器请求

##### 2. DNS查询

![img](D:\文件\markdown笔记\计算机网络.assets\v2-4e68ba51d411b26b607307dbd83a97ed_b.png)

依次从浏览器、操作系统、路由器、ISP查询是否有DNS缓存，如果都没有，本地DNS服务器会将请求转发到互联网的根域名服务器进行递归查询

##### 3. TCP连接

TCP/IP分为四层，每层都要对数据进行封装

![img](D:\文件\markdown笔记\计算机网络.assets\v2-6e7f3f12f414b1e970467f50c0062c6e_b.jpg)

**应用层：发送HTTP请求**

浏览器会根据IP地址构造一个HTTP报文，其中包括：

* 请求包头：请求方法、目标地址、遵循的协议等
* 请求主体

注意，浏览器只能发送GET、POST方法，而打开网页使用的是GET方法

**传输层：TCP传输报文**

传输层会发起一条到达服务器的TCP连接，为了方便传输，会对数据进行切割，并标记编号

* TCP三次握手

**网络层：IP协议和ARP协议**

IP协议是TCP/IP协议的核心，所有的TCP、UDP、ICMP、IGMP的数据都以IP数据格式传输。

注意:

>  IP协议不是可靠的协议，可靠性是TCP要做的事情

ARP是根据IP地址获取MAC地址的协议。主机要发送一个IP包的时候，先检查自己的ARP缓存，如果查询的IP-MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，收到广播包的所有主机都会查询自己的IP地址，如果符合条件，就发送一个包含自己MAC地址的ARP包给发送广播的主机

注意：

> OSI参考模型中，ARP协议位于链路层，而在TCP/IP中，它位于网络层

##### 4. 服务器处理请求

服务器接受TCP报文后，会对连接进行处理，对HTTP协议进行解析，并逐一验证

##### 5. 浏览器接受响应

浏览器接收到来自服务器的响应资源后，会对资源进行分析

首先查看Response Header，根据不同的状态码做不同的事；如果资源进行了压缩，还需要解压

然后对响应资源做缓存

##### 6. 渲染页面

解析HTML得到DOM树，然后使用CSS进行渲染，最后编译执行JavaScript

#### ping命令及ICMP协议

**ICMP协议**

ICMP(Internet Control Message Protocol)即控制报文协议，用于主机和路由器彼此交互网络层信息

ICMP最典型的用途是**差错报告**。例如运行FTP或HTTP会话时，可能会遇到诸如“目的网络不可达”之类的错误报文，这种报文就是ICMP中产生的。在某个位置，IP路由器不能找到一条路径，以通往目标主机，该路由器就会创建和发出一个ICMP报文到主机中来指示该错误

ICMP通常被认为是IP的一部分，但从体系结构上讲它是位于IP之上。因为ICMP报文是承载在IP分组中的，就像TCP或UDP报文段作为IP有效载荷被承载那样

**ping命令**

ping命令是基于ICMP协议来工作的

ping命令会发送一份ICMP回显请求报文给目标主机，并等待目标主机返回ICMP回显应答。因为ICMP协议要求目标主机在收到消息后，必须返回ICMP应答消息给源主机，如果源主机在一定时间内收到了目标主机的应答，则表明两台主机之间的网络是可达的

ping命令是应用层直接使用网络层ICMP的一个例子，它**没有通过传输层的TCP或UDP**

ping命令的过程：

1. 假设主机A输入命令：ping 192.168.0.2
2. ping命令会在主机A上构建一个ICMP的请求数据包，然后ICMP协议会将这个数据包以及目标IP等信息一同交给IP层协议
3. IP层协议收到后，将源IP地址、目标IP地址以及其他一些控制信息加进去，构建成一个IP数据包
4. 通过ARP协议找到当前子网网关对应的MAC地址，然后发送给网关
5. 网关层层转发到目标主机B的子网中，然后通过B的MAC地址发送给B

#### 对称加密与非对称加密

**对称加密**

加密：原文+密钥=密文

解密：密文-密钥=原文

也就是说，加密和解密使用的是同一个密钥，只是将操作逆过来

这样便会产生问题，因为双方通信之前必须要告知对方密钥，而如果密钥被第三方获知，之后的通信加密将失效

优点：算法简单，加密解密容易，效率高，执行快

常见的对称加密算法：AES、DES、3DES、RC3、RC4、RC4

**非对称加密**

即加密与解密用的是不同的密钥

假设B需要向A传输信息，A先给B一个公钥，自己保留私钥。B收到后通过**公钥加密**信息后传输，A收到后使用私钥进行解密。这样即使有第三方获得了公钥，也无法破解出B加密后数据的原文

缺点：加密算法复杂，安全性依赖于算法与密钥，加密与解密效率很低

通常**先用非对称加密传输对称加密的密钥，之后的通信通过对称加密进行**

常见的非对称加密算法：RSA、DSA、ECC

**不可逆加密**

对称加密与非对称加密都属于可逆加密的范畴，不可逆加密是指经过加密后的信息无法反向解析还原信息内容

例如为了保证用户资料的安全，存在数据库的用户密码一般是用不可逆的加密算法进行加密。这样即使系统管理员得到了加密后的密码，也无法得知真实密码

常见的不可逆加密算法：MD5、SHA、HMAC

#### 数字签名

即利用非对称加密，签名者A使用**私钥加密**信息得到签名，接收者B用公钥对签名进行解密，如果得到的结果与当前文档一致，则说明当前文档是真实的

但完全对数据进行加密或解密实在开销太大，一般A对源文件计算一个哈希值，再对哈希值进行加密，B对哈希值进行解密，并且用同样的哈希算法计算当前文件的哈希值，两者进行核对即可

一份文件包括数字签名+内容明文信息，每次只需要对数字签名进行核对，即可判断当前内容信息是否真实

#### 数字证书

其实非对称加密+对称加密的方式进行通信仍有漏洞，即可能被**中间人攻击**

1. 某网站拥有用于非对称加密的公钥A和私钥A'
2. 浏览器向网站服务器请求，服务器把公钥A明文传输给浏览器
3. 中间人劫持到公钥A，保存下来，将其换成自己的公钥B（它当然有对应的私钥B'）
4. 浏览器生成一个用于对称加密的密钥X，用收到的公钥B（被替换的）加密后传输给服务器
5. 中间人劫持到后，用私钥B‘解密得到密钥X，再用公钥A加密后给服务器
6. 服务器用私钥A’解密后得到密钥X

这样在双方都不会发现异常的情况下，中间人得到了后续用于加密传输的密钥X

关键问题就在于：

**如何证明浏览器收到的公钥一定是该网站的公钥？**

网站在使用HTTPS前，需要向**CA机构**申请一份数字证书，数字证书中的内容包括

1. 明文，包括网站的公钥A、网站ID等等
2. 使用CA机构的私钥C'生成的以上明文的数字签名

那么网站只需要将此数字证书发送给浏览器，浏览器使用CA机构的公钥C对数字签名进行验证，即可确定此公钥是否为网站的公钥A

这其中需要的前提是，**浏览器本地拥有CA机构的公钥**

**中间人有可能篡改该证书吗？**

有数字签名存在，篡改会被发现

**中间人有可能把证书掉包吗？**

因为证书中包含网站ID，所以无法掉包

**怎么证明CA机构的公钥是可信的？**

CA机构的公钥是否也可以用数字证书来证明？没错，操作系统、浏览器本身会预装一些它们信任的根证书，如果其中有该CA机构的根证书，那么就可以核查该CA机构的公钥是否可信

实际上，证书之间的认证可能也是一层套一层，例如A信任B，B信任C，这即为**信任链**或**数字证书链**

#### SSL和TLS

SSL(Security Socket Layer)即安全套接字层，SSL版本3的稍加修改版本称为TLS(Transport Layer Security)，即运输层安全性

SSL简化版本有三个阶段：握手，密钥导出和数据传输

以下假设A为浏览器，B为服务端

1. 握手

握手阶段A需要做三件事：(1)与B创建一个TCP连接，(2)验证B是真实的B，(3)发送给B一个密钥

![img](D:\文件\markdown笔记\计算机网络.assets\UVY69LHTP3LC_}X%C%HRC6U.png)

2. 密钥导出

B通过自己的私钥解密后，得到后续传输的主密钥，通常双方的数据传输会使用通过主密钥生成的多个密钥

3. 数据传输

#### Session和Cookie

[Session和Cookie以及HTTP应用的详细解释](https://www.cnblogs.com/lingyejun/p/9282169.html)

1. Session

由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态，就需要用某种机制来识别具体的用户，这个机制就是Session

典型的场景比如购物车，当我点击下提交按钮，由于HTTP协议无状态，所以并不知道是哪个用户操作的。因此服务端要为特定的用户创建特定的Session，用于标识这个用户，并且跟踪用户，这样才知道购物车里有什么内容

在服务端保存Session的方法有很多，内存、数据库、文件都有

2. Cookie

服务端如何识别特定的用户？这就需要Cookie。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端

实际上大多数应用都是用Cookie来实现Session跟踪。第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一下**Session ID**，以后每次请求的时候把这个会话ID发送到服务器，这样服务器就知道你是谁了

如果客户端的浏览器禁用了Cookie怎么办？一般这种情况下，会使用一种叫**URL重写**的技术来进行会话跟踪，即每次HTTP交互，URL后面都会附加一个诸如 sid = xxxx 这样的参数，服务端据此来识别用户

**另外**Cookie还可以用在一些方便用户的场景之下，假设某次登陆过一个网站，下次登录的时候不想再输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名密码给填了，能够方便用户。这也是Cookie名称的由来，即给用户一点甜头

3. 总结

Session是在服务端保存的一种数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中

Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式

另外，cookie是一个实际存在的、具体的东西，HTTP协议中定义在header中的字段；而Session是一个抽象概念，将客户端和服务的之间一对一的交互，抽象成“会话”，进而衍生出“会话状态”，也就是Session的概念
#### 进程、线程和协程

* 进程是具有一定功能的**程序**关于某个数据集合上的**一次运行活动**，它是系统进行资源调度和分配的一个独立单位
* 线程是进程的实体，是**CPU调度和分派的基本单位**，它是比进程更小的能独立运行的基本单位。一个进程有多个线程，多个线程也可以并发执行
* 协程是一种**用户态**的轻量级线程，协程的调度完全由用户控制。协程调度切换时，将寄存器上下文和栈保存到其他地方，再切换回来的时候，恢复原来的寄存器和栈。直接操作栈**基本没有内核切换的开销**，可以不加锁的访问全局变量，所以上下文切换非常快

**注意：**本质上，线程的内存空间是天然共享的。线程间同步是为了防止竞争（例如因同时修改而导致的数据不一致）；而进程的内存空间是天然独立的，因此需要进程通信

为什么需要协程？

就实际使用来讲，协程允许我们**用写同步代码的逻辑，去做异步的事情**，避免了回调嵌套，使得代码异常清晰。它是一种编程组件，可以在不陷入内核的情况下进行上下文切换

[关于线程和进程的解释--阮一峰](http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html) *留言处有更多精彩评论*

#### 进程可创建最大线程数

首先，不同的系统，线程的最大个数的定义不同；其次，线程个数与每个线程所占空间有关系

创建一个新线程时，它会占用系统资源（跟创建进程一样的效果，比如占用PID(Process Identifier)），也会占用进程内资源（比如线程栈就要占用一个VMA(Virtual Memory Address)），如果这两个资源任何一个超标了，都会造成创建线程失败

默认配置下，32位操作系统里，一个进程最多只能创建300+个线程，因为每个线程栈占用了8M，300+个线程栈占用内存将近3G了，将进程的虚拟空间占满了，所以创建新线程时失败

#### 线程同步的方式

* **互斥量**：通过**互斥锁Mutex**（Mutual exclusion)实现。采用互斥对象限制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
* **信号量Semaphore**：它允许同一个时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
* 事件（信号）：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较

[线程同步的几种方式](https://www.cnblogs.com/lebronjames/archive/2010/08/11/1797702.html)

#### 经典同步问题

[经典同步问题](https://cyc2018.github.io/CS-Notes/#/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%20-%20%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86?id=%e7%bb%8f%e5%85%b8%e5%90%8c%e6%ad%a5%e9%97%ae%e9%a2%98)

1. 生产者-消费者问题

生产者-消费者问题，又称为有限缓冲问题。该问题描述了两个共享固定大小缓冲区的线程，即生产者和消费者，它们在实际运行时会发生的问题。

生产者的作用是生成一定量的数据放入到缓冲区中，然后重复此过程。与此同时，消费者对缓冲区的数据进行消耗

那么需要保证，生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区空时消耗数据

解决方法：

缓冲区属于临界资源，因此需要一个**互斥量**`mutex`来控制对缓冲区的互斥访问。为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用**信号量**来进行统计，使用empty记录空缓冲区的数量，full记录满缓冲区的数量。当empty不为0时，生产者可以加入数据；当full不为0时，消费者才可以消耗数据

注意，不能先对缓存区加锁，再测试信号量。不然可能出现：生产者对缓冲区加锁，发现empty为0，此时生产者睡眠，而消费者无法进入临界区

2. 哲学家就餐问题

哲学家们围着一张圆桌坐着，每两人之间有一支筷子，每个人有两种交替活动：吃饭或思考。当一个哲学家要吃饭时，需要先拿起左右两支筷子，并且一次只能拿起一支

如果所有哲学家同时拿起左边的筷子，那么所有哲学家都在等待其他哲学家吃饭并放下筷子，导致**死锁**

为了防止死锁的发生，可以设置两个条件

* 必须同时拿起左右两支筷子
* 只有在两个邻居都没有吃饭的时候才能吃饭

3. 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生

解决方法：

一个整型变量count记录在对数据进行读操作的进程数量，一个互斥量count_mutex用于对count的加减加锁，一个互斥量data_mutex用于对读写的数据加锁

```c++
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() 
{
    while(TRUE) 
    {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() 
{
    while(TRUE) 
    {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}

```



#### 进程的通信方式

进程间通信(Inter Process Communication, IPC)

主要分为：管道、消息队列、信号量、共享存储、套接字SOCKET，前四种主要用于同一台机器上的进程间通信，而套接字主要用于不同机器之间的网络通信

1. 管道

* 本质就是文件，一个进程写，一个进程读，就实现了通信
* 管道是一种**半双工**的通信方式，数据只能单向流动。如果要进行双工通信，则需要建立两个管道
* 管道只能用于父子进程或兄弟进程间通信，也就是说管道只能用于具有亲缘关系的进程间通信

2. 命名管道FIFO

* FIFO也是半双工的通信方式，它可以在**无关的进程**之间交换数据，与无名管道不同
* 它以一种特殊设备文件形式存在于文件系统中

3. 消息队列

* 消息队列是一个在系统内核中用来保存消息的队列，它在系统内核中是以消息链表的形式出现
* 消息队列跟有名管道有不少相同之处，进行通信的进程可以是不相关的进程，

* 消息队列独立于发送与接收过程。进程终止时，消息队列及其内容不会被删除

4. 信号量

* 它与其他几种IPC方式不同，信号量是一个计数器，用于实现进程间的**互斥与同步**，通知接收进程某个事件已经发生，而不是存储进程间通信数据

5. 共享内存

* 共享内存是**最快的**一种IPC，因为进程是直接对内存进行存取
* 底层实现是，两个进程通过页表将虚拟地址映射到物理地址时，在物理地址中有一块共同的内存区，即共享内存，这块内存可以被两个进程同时看到。这样，当一个进程进行写操作，另一个进程进行读操作就可以看到
* 但是共享内存的**同步**问题自身无法解决，即进程何时该去共享内存取得数据，而何时不能取，这也是它的**缺点**。因此常与信号量结合使用

[进程间的几种通信方式](https://blog.csdn.net/yufaw/article/details/7409596)

#### 缓冲区溢出

什么是缓冲区？

因为计算机程序需要频繁地操作从文件、网络等各种来源读入一段数据，因此程序经常需要分配一段有限大小的内存空间，以便将数据存储在其中，这段内存空间便成为缓冲区

缓冲溢出是指计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上

缓冲区溢出也包括各种类型，如栈溢出、堆溢出等，主要关注的类型是**栈缓冲区溢出**

危害主要有：

* 程序崩溃，导致拒绝服务
* 跳转并执行一段恶意代码

缓冲区溢出的主要原因是程序中没有仔细检查用户输入

#### 死锁

在两个或多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗讲就是两个或多个进程**无限期的阻塞**、**相互等待**的一种状态

1. **死锁条件**

死锁产生有四个条件（有一个不成立，则不会产生死锁）

* 互斥条件：一个资源一次只能被一个进程使用
* 请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放
* 不剥夺条件：进程获得的资源，在未完全使用完之前，不能被强行剥夺
* 循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系

解决死锁的级别方法：

2. **预防死锁：**

* 资源的一次性分配：（破坏请求和保持条件）
* 可剥夺资源：当某个进程新的资源未满足时，释放已占用资源（破坏不可剥夺条件）
* 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏循环等待条件）

3. **避免死锁：**

预防死锁的几种策略会**严重损害系统性能**

在避免死锁的策略中，允许进程**动态地申请资源**。因而，系统在进行资源分配之前预**先计算资源分配的安全性**。若此次分配不会导致系统进入不安全状态，则将资源分配给进程，反之则进程等待

**银行家算法**是著名的死锁避免算法：

即按照进程执行序列，模拟分配资源，看是否每次都满足`进程需求的资源数≤剩余的资源数`，满足此条件的就是安全序列

4. **检测死锁：**

首先为每个进程和每个资源指定一个唯一的号码，然后建立**资源分配表**和**进程等待表**，根据死锁条件判断其中是否有环

5. **解除死锁：**

当发现有进程死锁后，便立即将它从死锁状态中解脱出来，常用方法有：

* 剥夺资源：从其他进程中剥夺足够数量的资源给死锁进程，以解除死锁状态
* 撤销进程：直接撤销死锁进程或其他撤销代价更小的进程

#### 进程的状态

* 就绪状态：进程已获得除处理机以外的所需资源，等待处理机资源
* 运行状态：占用处理机资源运行，处于此状态的进程数**小于等于CPU数**
* 阻塞状态：进程等待某种条件，在条件满足之前无法执行

进程三种状态之间的常见转换：

![img](D:\文件\markdown笔记\操作系统.assets\v2-3f4aadb10de757a548e60e3d86caf7aa_b.jpg)

* 就绪→运行：处于就绪状态的进程，当进程调度程序为之分配了处理机后，该进程便由就绪状态转变为运行状态
* 运行→就绪：运行过程中，因分配给它的一个时间片已经用完而不得不让出处理机，于是进程的状态转变为就绪
* 运行→阻塞：运行过程中，因等待某种事件的发生而无法进行执行，便转变为阻塞状态。例如等待键盘输入
* 阻塞→就绪：若等待的事件已经完成，便转变为就绪状态

#### 进程的调度算法

进程由**就绪状态**转为**运行状态**的过程就涉及到进程的调度

操作系统管理了系统的有限资源，当多个进程要使用这些资源时，必须按照一定的原则选择进程来占有程序，这就是进程调度

进程的调度方式：

* **不可剥夺（或不可抢占）方式**：一个进程在获得处理机后，除非运行结束或进入阻塞状态等原因主动放弃CPU，否则一直运行下去
* **可剥夺方式**：在某些条件下，系统可以强制剥夺正在运行的进程使用处理机的权利，将其分配给另一个合适的就绪进程

常用的进程调度算法：

1. **先来先服务FCFS(First Come First Serve)调度算法**

不可抢占性；不能为紧急进程优先分配CPU，很少单独使用

优化方案：

* 可以在同一个优先级上采用

2. **时间片轮转法**

各就绪进程运行一小段时间，这一小段时间称为一个**时间片**。如果时间片过大，系统与用户间的交互性变差，用户响应长；如果时间片过小，进程间切换过于频繁，系统开销增大

当一个进程耗费完一个时间片而尚未执行完毕，调度程序就强迫它放弃处理机，使其重新排到就绪队列末尾

可剥夺式调度算法

优化方案：

* 将时间片分成多个规格
* 按时间片大小将就绪进程排成多个队列，将交互性强的进程排在小时间片队列，而计算性强的进程排在长时间片队列

* 将需要连续占用处理机的进程安排在时间片长的队列中，这样可以减少进程切换的开销

3. **优先级调度算法**

为每个进程赋予一个优先数，用于表示进程的优先级；调度程序总是从就绪队列中挑选一个优先级最高的进程，使之占有处理机

静态优先级：在进程创建时就赋予了优先数，之后运行期间保持不变

* 系统进程应当比用户进程有更高的优先级
* 短作业的进程应该有更高优先级
* I/O繁忙的进程应当有更高的优先级

动态优先级：进程的优先级在运行过程中根据其不同状态而变化

* I/O阶段提高其优先级，大规模运算阶段，降低其优先级
* 占用CPU时间越长，就可降低其优先级；在就绪队列中等待时间越长，就可升高其优先级

4. **最短作业(SJF)优先调度算法**

根据进程提供的估计执行时间来选择所需时间最少的优先执行

SJF算法是**平均等待时间和平均周转时间最少**的算法

缺点：

* 未考虑作业的紧迫程度
* 算法对长作业不利
* 估计运行时间可能并不准确

#### 虚拟内存

[什么是虚拟内存？|一分钟系列](https://zhuanlan.zhihu.com/p/85760403)

使用虚拟内存的原因：

* 为了避免进程访问自己的内存空间时越界，采用虚拟内存实现了进程之间地址空间的隔离
* 程序运行时的地址不确定。因为程序每次要运行的时候，都是需要装载到内存中的，所在地址是不确定的。假设程序中写死了某个要操作的地址，那么就有可能会出问题

因此，操作系统给进程分配了虚拟内存空间，并且由操作系统负责将虚拟内存地址映射到实际内存地址

内存空间不够用了，操作系统将一些程序存储到硬盘空间，例如一些很久都不需要运行的程序，当它们需要使用的时候，再从硬盘加载到真实内存中

对于程序员来说，虚拟内存就是一个字节数组，这个字节数组也被划分为很多部分

![img](D:\文件\markdown笔记\操作系统.assets\v2-52fae7977dd218ba36159af8a92ea6c1_720w.jpg)

#### 内部碎片和外部碎片

1. 外部碎片

外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域

产生原因：内存没有进行很好的分区管理

解决方法：内存分段或分页

2. 内部碎片

内部碎片就是已经被分配出去（明确属于某个进程）却不能被利用的空间

产生原因：由于采用固定大小的内存分区，当一个进程不能完全使用分给它的固定内存区域时就产生了内部碎片，通常**内部碎片难以避免**，但采取更小的分区块进行分区，可以减小内部碎片

#### 内存分段和分页

分页和分段是虚拟地址映射到实际内存地址的两种方式，其区别在于：

* 分段是将虚拟内存按照数据段、代码段、堆栈段等进行到实际内存的映射，其每一段有特定意义，长度不同
* 而分页是将程序分成等长的小块，这些小块叫做**页(Page)**，同样内存也被分成了和页面同样大小的**页框(Frame)**，一个页可以装到一个页框中，在执行程序的时候根据一个页表去查找某个页面在内存的某个页框中，由此完成从逻辑到物理的映射

分段和分页管理都属于内存的**不连续分配**，最大的区别在于，分页对于用户来说是没什么逻辑意义的，只是为了完成离散式存储，所有的页面大小都一样；而分段有时在编译过程中会指定划分，因此可以保留部分逻辑特征，容易实现分段共享

分段由于段的长度不等，容易出现较大的**内存碎片**，所以出现了分页方法

页面大小应该适中，如果页面太小，会使得进程的页面数过多，页表过长，占用大量内存，而且会增加地址转换的开销，降低页面转入转出的效率；如果页面太大，会使得页面碎片增大，降低内存的利用率

![img](D:\文件\markdown笔记\操作系统.assets\v2-db98afd6d5e107bba50547f1759dbd36_720w.jpg)

**段页式管理方式**

地址空间先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分成若干大小固定的页



#### C语言内存分区(进程地址分区)

C语言开发对内存使用有区域划分，分别是**栈区(stack)**、**堆区(heap)**、**全局数据区**、**文字常量区**和**代码段(text)**

![img](D:\文件\markdown笔记\操作系统.assets\v2-deb39dc05a514a6e3bcf5751be932846_b.jpg)

* 栈区：函数中定义变量存放的区域，例如常见的`int/float/char`等变量，以及指针变量，**const修饰的局部变量**也位于栈区。它的特点是由系统自动分配和释放，不需要程序员考虑资源回收的问题，方便简洁。注意：栈区的地址分配是从内存的高地址开始向低地址分配，是**连续的**
* 堆区：通过指令自主向系统申请的区域，大小由自己决定，在使用完之后需要自己通过指令去释放该区域内存，否则可能出现内存泄露，C语言中即`malloc/free`。堆中的内存空间**不是连续的**
* 全局数据区：内部分为BSS段和数据段
  * bss(Block Started by Symbol)段：通常是存放程序中**未初始化**的全局变量和`static`静态变量的一块内存区域，bss段属于静态内存分配。若未初始化，系统会自动将其值设置为0。在C++中，无论是否初始化，都存放在这
  * 数据段：C语言全局变量和静态变量初始化之后，存放在这
* 文字常量区：例如常量字符串“ABC"，以及**const修饰的全局变量**
* 代码段：代码段通常是指用来存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域通常属于**只读**

> 注意：进程中的每个线程可以共享代码段和数据段，但是都有自己的堆栈段

#### malloc和free原理

1. malloc原理

从操作系统角度来看，进程分配内存有2种方式，分别由2个系统调用完成：`brk`和`mmap`

* `brk`是将数据段最高地址指针往高地址推
* `mmap`是在进程的虚拟地址空间中（堆和栈中间，文件映射区）找一块空闲的虚拟内存

注意，进程分配的内存都是**虚拟内存**，不是物理内存。在第一次访问已分配的虚拟空间地址时，发生缺页中断，然后操作系统给分配物理内存

**小于128K内存分配**

使用`brk`分配内存

![img](D:\文件\markdown笔记\操作系统.assets\20171017215810378.jpg)

但这样很容易产生碎片，因为堆是从低地址到高地址，如果低地址的内存没有释放，高地址的内存就不能被回收

**大于128K内存分配**

使用`mmap`分配内存，在堆和栈之间找一块空闲内存分配

![img](D:\文件\markdown笔记\操作系统.assets\20171017215827877.jpg)

`mmap`函数有两种用法，一种是映射磁盘文件到内存中，用于进程通信；而malloc使用的是另一种用法，即匿名映射，它不映射任何磁盘文件，而是向映射区申请一块内存



#### 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生**缺页中断**。当发生缺页中断时，如果操作系统内存中没有空闲空间，则操作系统必须在内存中选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法，其作用是为了实现虚拟存储管理

1. **OPT页面置换算法（最优页面置换算法）**

基本思路：当一个缺页中断发生时，对于保存在内存中的每一个逻辑页面，计算它在下一次访问之前，**还需要等待多长的时间**，从中选择等待时间最长的那个，作为被置换的页面

这是一种理想情况，不可能实现，一般作为评价其他置换算法的方法

2. **FIFO页面置换算法（先进先出页面置换算法）**

总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰

缺点：FIFO是思路与置换算法的目标是不一致的，置换算法目的是希望替换较少使用的页面，而FIFO置换出去的页面不一定是进程使用较少的

3. **LRU页面置换算法（最近未使用页面置换算法）**

LRU(Least Currently Used)，思路是选择最久未使用的页面予以淘汰，它是对最优置换算法的近似，以过去推断未来

实现思路：维护一个页面链表，最近刚使用的页面作为首节点，最久未使用的页面作为尾结点。每次访问内存时，找到相应的页面，把它从链表中摘下来，再移动到链表之首。每当缺页发生时，淘汰链表末尾的页面

缺点：LRU算法需要记录各个页面使用时间的先后顺序，开销较大

4. **LFU页面置换算法（最少使用页面排序算法）**

LFU(Least Frequently Used)，思路是选择访问次数最少的那个页面淘汰

实现思路：对每个页面设置一个访问计数器，每当一个页面被访问时，该页面的访问计数器+1，淘汰计数值最小的那个页面

缺点：如果页面在进程开始时使用很多，但以后就不使用了，LFU就不适合

#### 抖动与工作集

**抖动**

在页面置换过程中的一种最糟糕的情形是，刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存，这种**频繁的页面调度行为**称为抖动，或颠簸

频繁的发生缺页中断，其主要原因是某个进程频繁访问的页面数目高于可用的物理页面数目

**工作集（驻留集）**

工作集是指在某段时间内，进程要访问的页面集合。经常被使用的页面需要在工作集中，而长期不被使用的页面要从工作集中被丢弃。为了防止系统出现抖动现象，需要选择合适的工作集大小

工作集模型的原理是，让操作系统跟踪每个进程的工作集，并为进程**分配大于其工作集的物理块**。如果还有空闲物理块，则可以再调一个进程到内存中。如果所有工作集之和超过了可用物理块的总数，那么操作系统会暂停一个进程，将其页面调出并且将其物理块分配给其他进程，防止出现抖动现象

#### 程序从开始运行到结束的四个过程

![img](D:\文件\markdown笔记\操作系统.assets\X_J4KFIF0]C1Z80T}2XNGP.png)

1. 预处理

主要处理文件中`#开头的代码`

* 删除所有`#define`，展开所有宏定义
* 处理所有的条件预编译指令，如`#if`、`#endif`
* 处理`#include`预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中可能还包含其他文件
* 删除所有注释，`//`和`/**/`
* 保留所有`#progma`编译器指令，编译器需要用到它们，例如，`#progma once`是为了防止有文件被重复包含

注意，宏替换和文件包含的工作，不归入编译器的范围，而是交给独立的预处理器

2. 编译

代码被翻译成**汇编语言**

3. 汇编

将`.s`文件翻译成二进制机器指令文件，Linux为`.o`文件，Windows为`.obj`文件。文件是**二进制文件**，如果直接用文本工具打开将看到乱码

注意，`.h`文件中都是声明，不会被编译进去，它的内容只是以列表的形式存在，这个表在链接的时候会用到

4. 链接

链接就是将各个模块彼此连接，链接的过程主要包括地址和空间的分配

链接过程将一堆目标文件装配成**静态库**或**动态库**，这可以自行选择

* 静态库是指编译链接时，把库文件的代码全部加入到可执行文件中，因此生成的文件比较大，但运行时也就不再需要库文件了，速度较快

* 动态库与之相反，在编译连接时并没有把库文件的代码加入到可执行文件中，而是在程序执行时加载，这样可以节省系统开销，但速度慢

最终生成**可执行文件**，即可以直接加载到操作系统内存中，由操作系统加载并执行

#### 静态链接和动态链接

静态链接和动态链接最大的区别在于，二者链接的时机不一样。静态链接是在形成可执行程序前，而动态链接则是在程序执行时

1. 静态链接

即将所有引用到的函数所在的库文件全部包含进来，压缩打包在一起形成一个文件

![img](D:\文件\markdown笔记\操作系统.assets\20180505235327609)

优点：在可执行程序中已经具备了所有可执行程序所需要的任何东西，在执行的时候速度更快

缺点：一是浪费空间，例如假设有多个程序都调用了`printf()`，则这多个程序中都含有`printf.o`，所以同一个目标文件在内存中会存在多个副本；另一方面是更新比较困难，因为每当库函数的代码修改了，就需要重新进行编译链接形成可执行程序

2. 动态链接

即把程序按照模块拆分成各个相对独立的部分，在程序**执行时**才将它们链接在一起形成一个完整的程序

优点：一是节省空间，假设多个程序都调用了`printf()`，程序中只会有一份`printf.o`，所有程序在执行时共享同一份副本；另一个就是更新方便，更新时只需要替换修改的文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的文件会自动被加载到内存中并且链接起来

缺点：每次程序运行时才进行链接，速度会慢一些



#### 用户态和内核态

##### 用户态与内核态的区别

用户态和内核态是操作系统的**两种运行级别**

当一个任务（进程）执行系统调用而陷入内核代码中执行时，就称进程处于内核运行态，简称内核态，其他的属于用户态。用户程序运行在用户态，操作系统运行在内核态

用户态不能干扰内核态，所以CPU指令就有两种，**特权指令**和**非特权指令**，不同的状态对应不同的指令。特权指令只能由操作系统内核部分调用，不允许用户直接使用

所以，内核态执行全部指令，而用户态执行非特权指令

##### 为什么要区分用户态和内核态

是为了保护操作系统。因为操作系统中的一些重要数据，是不允许修改和破坏的

##### 用户态切换到内核态的方式

1. 系统调用

这是用户态进程**主动要求切换**到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。这也是操作系统提供给应用程序使用内核功能的接口，是用户取得操作系统服务的唯一途径

2. 异常

当CPU在执行用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常

3. 外围设备的中断

当外围设备完成用户请求的操作时，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行与中断信号对应的处理程序。如果先前执行的指令是用户态下的程序，那么这个转换自然就发生了由用户态到内核态的切换。比如硬盘读写操作完成

#### 异常和中断

**中断**

由于出现**外部事件**，CPU暂停正在执行的程序，在保留现场后自动地去执行该事件的中断处理程序。执行完毕后，再返回到原程序的断点处继续执行

**异常**

是指CPU执行了**现行指令**所引起的，由于系统调用引起的中断都属于异常

总结

相同点：异常和中断都是**CPU**对系统发生的某个事情做出的一种反应

不同点：中断是外因引起的，而异常是由于CPU本身原因引起的

![img](D:\文件\markdown笔记\操作系统.assets\20190328033536613.png)



#### 线程池

线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务

为什么要用线程池？

* 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗
* 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行
* 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配、调优和监控

#### 僵尸进程/孤儿进程/守护进程

**父进程与子进程**

在Linux中，除了进程0(即**PID=0**的进程)除外的所有进程都是由其他进程使用系统调用`fork()`创建而成的，这里调用`fork()`创建新进程的进程即为父进程，而相对应的其创建出的进程即为子进程。因而除了进程0以外的所有进程都只有一个父进程，但一个进程可以有多个子进程

子进程和父进程的运行是一个**异步**的状态，即父进程永远无法预测子进程到底什么时候结束。当一个进程完成它的工作终止以后，它的父进程需要调用`wait()`或者`waitpid()`系统调用取得子进程的终止状态

**孤儿进程**

一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被**init进程** **PID=1**所收养，并且由init进程对它们完成状态收集工作

孤儿进程没有父进程，那么父进程要执行的`wait()/waitpid()`的重任就落在了init进程上

孤儿进程并**没有什么危害**

**僵尸进程**

一个进程使用`fork()`创建子进程，如果子进程退出，而父进程并没有调用`wait()`或`waitpid()`获取子进程的状态信息，那么子进程的状态描述符仍然保留在系统里，它就进入僵死状态

问题及危害：

Unix提供了一种机制可以保证只要父进程想要知道子进程结束时的状态，就可以得到。这种机制就是，在每个进程退出的时候，内核释放该进程的所有资源，包括打开的文件、占用的内存等。但仍然为其保留了一部分信息，包括**进程号PID**、**退出状态**、**运行时间等**，直到父进程通过`wait()/waitpid()`来取时才释放

但如果父进程没有调用`wait()/waitpid()`的话，那么保留的那段信息就不会释放，其进程号就会一直被占用。但系统的**进程号是有限**的，如果出现大量的僵尸进程，将可能因为没有可用的进程号而导致系统无法创建新的进程

僵尸进程处理方式：

找到这些僵尸进程的父进程，将父进程关闭，那么它产生的僵尸进程就变成孤儿进程，这些僵尸进程会被init进程接管，从而释放资源

**守护进程**

守护进程是一类脱离终端在后台执行的程序，通常以d结尾，随系统启动，其父进程通常是init进程

#### Linux常用命令

1. `cd <路径>`

切换到当前文件夹

2. `ls <参数> <路径>`

列出当前目录下所有文件

3. `cat <文件>`

表示读取文件内容

4. `rm <文件>`或`rm -r <文件夹>`

删除文件或文件夹

5. `mkdir <文件夹>`

创建文件夹

#### 锁机制

1. 互斥锁

用于控制多个线程对他们之间共享资源互斥访问的一个信号量，也就是说为了避免多个线程在某个时刻同时操作一个共享资源

在某一个时刻，只有一个线程可以获取互斥锁，在释放互斥锁之前其他任何线程都不能获取该互斥锁。如果其他线程想要获取这个互斥锁，那么这个线程只能以阻塞方式进行等待

2. 条件锁（条件变量）

条件锁就是所谓的条件变量，条件变量是用来等待的，而不是上锁的。某一个线程因为某个条件为满足使得该线程处于阻塞状态，直到此条件不成立才能被唤醒

条件锁通常和互斥锁结合使用

3. 自旋锁

首先要与互斥锁区分，**互斥锁是一种sleep-waiting的锁**。假设线程T1获取互斥锁并且正在处理器core1上运行时，线程T2也想要去获取互斥锁，那么T2将被阻塞。当T2处于阻塞状态时，T2倍放入到等待队列中去，处理器core2会去处理其他任务而不必一直等待

而自旋锁不同，自旋锁是一种**busy-waiting的锁**。也就是说，如果T1正在使用自旋锁，而T2也去申请这个自旋锁，那么T2将被阻塞。但与互斥锁不同的是，此时运行T2的处理器core2会一直不断地循环检查锁是否可用，直到获取到这个自旋锁为止

自旋锁是比较耗费CPU的

自旋锁的使用场景：锁的持有时间比较短时

4. 读写锁

简单来说，我们只允许对同一个文件同时执行多个“读”操作，但在某一时刻只能有一个“写”操作去更新数据

读写锁的特点：

* 如果有线程读数据，则允许其他线程执行读操作，但不允许写操作
* 如果有线程在写数据，则其他线程的读、写都不允许

5. 信号量

信号量本质是一个非负的整数计数器，它被用来控制对公共资源的访问